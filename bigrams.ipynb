{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21275/3157197756.py:7: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_21275/3157197756.py:8: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f7ed755aa60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN_COLAB = False\n",
    "print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "# Code to automatically update the EasyTransformer code as its edited without restarting the kernel\n",
    "ipython.magic(\"load_ext autoreload\")\n",
    "ipython.magic(\"autoreload 2\")\n",
    "\n",
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtyping import TensorType as TT\n",
    "from typing import List, Union, Optional, Tuple\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "from torchtyping import TensorType\n",
    "\n",
    "import circuitsvis\n",
    "from circuitsvis import attention\n",
    "\n",
    "import easy_transformer\n",
    "import easy_transformer.utils as utils\n",
    "from easy_transformer.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from easy_transformer import EasyTransformer, EasyTransformerConfig, FactoredMatrix, ActivationCache\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: NeelNanda/SoLU_1L512W_C4_Code\n",
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model NeelNanda/SoLU_1L512W_C4_Code into EasyTransformer!\n",
      "Loading model: NeelNanda/Attn_Only_1L512W_C4_Code\n",
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model NeelNanda/Attn_Only_1L512W_C4_Code into EasyTransformer!\n"
     ]
    }
   ],
   "source": [
    "model = EasyTransformer.from_pretrained(\n",
    "    \"NeelNanda/SoLU_1L512W_C4_Code\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "attn_model = EasyTransformer.from_pretrained(\n",
    "    \"NeelNanda/Attn_Only_1L512W_C4_Code\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    "    device=\"cpu\"\n",
    "    )\n",
    "\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48261/48261 [09:49<00:00, 81.83it/s] \n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "# 48261\n",
    "for tokenIndex in tqdm(range(48261)):\n",
    "    # Get the token\n",
    "    token = tokenizer.decode(tokenIndex)\n",
    "    \n",
    "    # Initialise the token details\n",
    "    details = {\n",
    "        \"idx\": tokenIndex,\n",
    "        \"token\": token,\n",
    "    }\n",
    "    \n",
    "    # Get the top k logits & corresponding tokens\n",
    "    logits = model(token)[0][1]\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    _, topKTokens = torch.topk(probs, 10, largest=True)\n",
    "    \n",
    "    for idx, token_idx in enumerate(topKTokens):\n",
    "        token_idx = token_idx.item()\n",
    "        token = tokenizer.decode(token_idx)\n",
    "        prob = probs[token_idx]\n",
    "        \n",
    "        # Add to the details\n",
    "        details[f\"top_{idx}_idx\"] = token_idx\n",
    "        details[f\"top_{idx}_token\"] = token\n",
    "        details[f\"top_{idx}_prob\"] = prob.item()\n",
    "    \n",
    "    # Add to tokens list\n",
    "    tokens.append(details)\n",
    "    \n",
    "# Convert to a dataframe\n",
    "bigrams = pd.DataFrame(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>token</th>\n",
       "      <th>top_0_idx</th>\n",
       "      <th>top_0_token</th>\n",
       "      <th>top_0_prob</th>\n",
       "      <th>top_1_idx</th>\n",
       "      <th>top_1_token</th>\n",
       "      <th>top_1_prob</th>\n",
       "      <th>top_2_idx</th>\n",
       "      <th>top_2_token</th>\n",
       "      <th>...</th>\n",
       "      <th>top_6_prob</th>\n",
       "      <th>top_7_idx</th>\n",
       "      <th>top_7_token</th>\n",
       "      <th>top_7_prob</th>\n",
       "      <th>top_8_idx</th>\n",
       "      <th>top_8_token</th>\n",
       "      <th>top_8_prob</th>\n",
       "      <th>top_9_idx</th>\n",
       "      <th>top_9_token</th>\n",
       "      <th>top_9_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17857</th>\n",
       "      <td>17857</td>\n",
       "      <td>pcbi</td>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>0.999555</td>\n",
       "      <td>533</td>\n",
       "      <td>which</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>593</td>\n",
       "      <td>so</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>345</td>\n",
       "      <td>he</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>328</td>\n",
       "      <td>on</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>276</td>\n",
       "      <td>in</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28707</th>\n",
       "      <td>28707</td>\n",
       "      <td>fasterxml</td>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>0.999089</td>\n",
       "      <td>28</td>\n",
       "      <td>:</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>65</td>\n",
       "      <td>_</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>25438</td>\n",
       "      <td>jackson</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>15</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>348</td>\n",
       "      <td>as</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28893</th>\n",
       "      <td>28893</td>\n",
       "      <td>umbre</td>\n",
       "      <td>619</td>\n",
       "      <td>ll</td>\n",
       "      <td>0.998891</td>\n",
       "      <td>252</td>\n",
       "      <td>on</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>14392</td>\n",
       "      <td>lla</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>68</td>\n",
       "      <td>b</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>2139</td>\n",
       "      <td>ley</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1055</td>\n",
       "      <td>led</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46091</th>\n",
       "      <td>46091</td>\n",
       "      <td>HepG</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995836</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>15</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28110</th>\n",
       "      <td>28110</td>\n",
       "      <td>surfact</td>\n",
       "      <td>1086</td>\n",
       "      <td>ants</td>\n",
       "      <td>0.995655</td>\n",
       "      <td>250</td>\n",
       "      <td>in</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>386</td>\n",
       "      <td>ant</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>834</td>\n",
       "      <td>ating</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>422</td>\n",
       "      <td>ive</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>312</td>\n",
       "      <td>ol</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30790</th>\n",
       "      <td>30790</td>\n",
       "      <td>courty</td>\n",
       "      <td>2130</td>\n",
       "      <td>ards</td>\n",
       "      <td>0.994725</td>\n",
       "      <td>12715</td>\n",
       "      <td>arded</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>472</td>\n",
       "      <td>ard</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>680</td>\n",
       "      <td>ata</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>1172</td>\n",
       "      <td>yl</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21543</th>\n",
       "      <td>21543</td>\n",
       "      <td>pione</td>\n",
       "      <td>398</td>\n",
       "      <td>ers</td>\n",
       "      <td>0.994663</td>\n",
       "      <td>255</td>\n",
       "      <td>er</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>15</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>675</td>\n",
       "      <td>erv</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>258</td>\n",
       "      <td>en</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>276</td>\n",
       "      <td>in</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>39769</td>\n",
       "      <td>googleapis</td>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>0.994287</td>\n",
       "      <td>65</td>\n",
       "      <td>_</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>15034</td>\n",
       "      <td>\\.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>41220</td>\n",
       "      <td>-%</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>17</td>\n",
       "      <td>/</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>3</td>\n",
       "      <td>!</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17490</th>\n",
       "      <td>17490</td>\n",
       "      <td>fibrobl</td>\n",
       "      <td>3153</td>\n",
       "      <td>astic</td>\n",
       "      <td>0.994141</td>\n",
       "      <td>1317</td>\n",
       "      <td>cells</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>10</td>\n",
       "      <td>(</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>19987</td>\n",
       "      <td>astically</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>13687</td>\n",
       "      <td>orer</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5817</th>\n",
       "      <td>5817</td>\n",
       "      <td>https</td>\n",
       "      <td>1333</td>\n",
       "      <td>://</td>\n",
       "      <td>0.993413</td>\n",
       "      <td>28</td>\n",
       "      <td>:</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>3</td>\n",
       "      <td>!</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>15</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>286</td>\n",
       "      <td>and</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx       token  top_0_idx top_0_token  top_0_prob  top_1_idx  \\\n",
       "17857  17857        pcbi         16           .    0.999555        533   \n",
       "28707  28707   fasterxml         16           .    0.999089         28   \n",
       "28893  28893       umbre        619          ll    0.998891        252   \n",
       "46091  46091        HepG         20           2    0.995836         21   \n",
       "28110  28110     surfact       1086        ants    0.995655        250   \n",
       "30790  30790      courty       2130        ards    0.994725      12715   \n",
       "21543  21543       pione        398         ers    0.994663        255   \n",
       "39769  39769  googleapis         16           .    0.994287         65   \n",
       "17490  17490     fibrobl       3153       astic    0.994141       1317   \n",
       "5817    5817       https       1333         ://    0.993413         28   \n",
       "\n",
       "      top_1_token  top_1_prob  top_2_idx top_2_token  ...  top_6_prob  \\\n",
       "17857       which    0.000081        593          so  ...    0.000013   \n",
       "28707           :    0.000374         65           _  ...    0.000024   \n",
       "28893          on    0.000132      14392         lla  ...    0.000032   \n",
       "46091           3    0.001424         19           1  ...    0.000088   \n",
       "28110          in    0.002054        386         ant  ...    0.000078   \n",
       "30790       arded    0.001346        472         ard  ...    0.000114   \n",
       "21543          er    0.001585         15           -  ...    0.000089   \n",
       "39769           _    0.001472      15034          \\.  ...    0.000288   \n",
       "17490       cells    0.000845         10           (  ...    0.000100   \n",
       "5817            :    0.003046         16           .  ...    0.000045   \n",
       "\n",
       "       top_7_idx top_7_token  top_7_prob  top_8_idx top_8_token  top_8_prob  \\\n",
       "17857        345          he    0.000011        328          on    0.000009   \n",
       "28707      25438     jackson    0.000020         15           -    0.000020   \n",
       "28893         68           b    0.000030       2139         ley    0.000028   \n",
       "46091         16           .    0.000079         15           -    0.000059   \n",
       "28110        834       ating    0.000074        422         ive    0.000045   \n",
       "30790         16           .    0.000113        680         ata    0.000074   \n",
       "21543        675         erv    0.000089        258          en    0.000089   \n",
       "39769      41220          -%    0.000228         17           /    0.000198   \n",
       "17490      19987   astically    0.000086         16           .    0.000077   \n",
       "5817           3           !    0.000043         15           -    0.000041   \n",
       "\n",
       "       top_9_idx top_9_token  top_9_prob  \n",
       "17857        276          in    0.000009  \n",
       "28707        348          as    0.000020  \n",
       "28893       1055         led    0.000028  \n",
       "46091         26           8    0.000054  \n",
       "28110        312          ol    0.000042  \n",
       "30790       1172          yl    0.000068  \n",
       "21543        276          in    0.000079  \n",
       "39769          3           !    0.000116  \n",
       "17490      13687        orer    0.000076  \n",
       "5817         286         and    0.000040  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams.sort_values(\"top_0_prob\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    48261.000000\n",
       "mean         0.193992\n",
       "std          0.163758\n",
       "min          0.005995\n",
       "25%          0.091559\n",
       "50%          0.143002\n",
       "75%          0.227320\n",
       "max          0.999555\n",
       "Name: top_0_prob, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams[\"top_0_prob\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "bigrams.to_csv(\"bigrams.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate prompts to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcbi .\n",
      "fasterxml .\n",
      " umbre ll\n",
      " HepG 2\n",
      " surfact ants\n",
      " courty ards\n",
      " pione ers\n",
      "googleapis .\n",
      " fibrobl astic\n",
      " https ://\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompts = []\n",
    "answers_correct = []\n",
    "answers_incorrect = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for _idx, row in bigrams.sort_values(\"top_0_prob\", ascending=False).iterrows():\n",
    "    # Get the token & most likely next tokens\n",
    "    token = str(row[\"token\"])\n",
    "    most_likely = str(row[\"top_0_token\"])\n",
    "    less_likely = str(row[\"top_1_token\"]) # Can change to 1-9 \n",
    "    \n",
    "    \n",
    "    print(token, most_likely)\n",
    "    \n",
    "    # Create the prompt\n",
    "    prompts.append(token)\n",
    "    answers_correct.append(most_likely)\n",
    "    answers_incorrect.append(less_likely)  \n",
    "    \n",
    "    i += 1\n",
    "    if i >= 10:\n",
    "        break  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attn vs SoLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 49.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 48262])\n",
      "torch.Size([1, 2, 48262])\n",
      "torch.Size([1, 2, 48262])\n",
      "torch.Size([1, 2, 48262])\n",
      "torch.Size([1, 2, 48262])\n",
      "torch.Size([1, 2, 48262])\n",
      "torch.Size([1, 2, 48262])\n",
      "torch.Size([1, 2, 48262])\n",
      "torch.Size([1, 2, 48262])\n",
      "torch.Size([1, 2, 48262])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1.000000e+01\n",
       "mean     3.991859e-01\n",
       "std      5.146846e-01\n",
       "min      8.829575e-07\n",
       "25%      9.193277e-06\n",
       "50%      1.532977e-03\n",
       "75%      9.954492e-01\n",
       "max      9.995549e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs = []\n",
    "solu_res = []\n",
    "attn_res = []\n",
    "\n",
    "for idx, prompt in tqdm(enumerate(prompts)):\n",
    "    answer = answers_correct[idx]\n",
    "    answer_token = model.to_single_token(answer[0])\n",
    "\n",
    "    solu_logits = model(prompt)\n",
    "    attn_logits = attn_model(prompt)\n",
    "    \n",
    "    solu_last_logits = solu_logits[0][1]\n",
    "    attn_last_logits = attn_logits[0][1]\n",
    "    \n",
    "    solu_probs = F.softmax(solu_last_logits, dim=-1)\n",
    "    attn_probs = F.softmax(attn_last_logits, dim=-1)\n",
    "    \n",
    "    solu_correct_prob = solu_probs[answer_token]\n",
    "    attn_correct_prob = attn_probs[answer_token]\n",
    "    \n",
    "    diff = solu_correct_prob - attn_correct_prob\n",
    "    \n",
    "    diffs.append(diff.item())\n",
    "    solu_res.append(solu_correct_prob.item())\n",
    "    attn_res.append(attn_correct_prob.item())\n",
    "\n",
    "    \n",
    "diffs_series = pd.Series(diffs)\n",
    "solu_res_series = pd.Series(solu_res)\n",
    "attn_res_series = pd.Series(attn_res)\n",
    "\n",
    "# Show summary statistics\n",
    "solu_res_series.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daf231521c125af094d5066265592d6b64cf3d2c4d3459f02d2b6825d3ed03e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
