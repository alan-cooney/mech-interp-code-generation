{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "031e47c8-3024-4865-8fb3-6429af0f8bbf",
   "metadata": {},
   "source": [
    "# SoLU Circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb718ae-d144-4c98-b3dc-0a230f8a46cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "08a22465-7f12-4158-bd35-721465c374e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import gc\n",
    "import html\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from functools import partial\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import datasets\n",
    "import einops\n",
    "import gdown\n",
    "import ipywidgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm.auto as tqdm\n",
    "import tqdm.notebook as tqdm\n",
    "import transformers\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from easy_transformer.EasyTransformer import (MLP, Attention, EasyTransformer,\n",
    "                                              Embed, LayerNorm, PosEmbed,\n",
    "                                              TransformerBlock, Unembed)\n",
    "from easy_transformer.EasyTransformerConfig import EasyTransformerConfig\n",
    "from easy_transformer.hook_points import HookedRootModule, HookPoint\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import clear_output, display\n",
    "from rich import print\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Fix for pysvelte import bug\n",
    "sys.path.append('/workspaces/solu-circuits/PySvelte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3519fc-4b88-4f76-a6a0-25b0751a7ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this after the above fix\n",
    "import pysvelte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fb5832-1076-4dea-aad6-cd12a30a2ea0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8bc566-a58d-4395-b198-a3c42221ac2c",
   "metadata": {},
   "source": [
    "### Config\n",
    "\n",
    "Given that we're using a checkpoint of a model that has already been run, we add in the config settings from that model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b92a3b-4988-42f0-a03f-31af959d7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EasyTransformerConfig settings\n",
    "cfg = {\n",
    "    'd_model': 1024,\n",
    "    'd_head': 64,\n",
    "    'n_layers': 1,\n",
    "    'n_ctx': 1024,\n",
    "    'd_vocab': 50278,\n",
    "    'use_attn_result': False,\n",
    "    'act_fn': 'solu_ln',\n",
    "    'eps': 1e-5,\n",
    "    # The trained model used LN everywhere, except for RMS just before \n",
    "    # the final unembedding. We switch to LNPre (folding in the weights/biases\n",
    "    # to the next weights), and then manually override the final RMS normalization\n",
    "    # to be RMSPre in the code below. See the 'Fold in weights and biases' section\n",
    "    # for more details.\n",
    "    'normalization_type': 'LNPre',\n",
    "    \"model_name\": \"SoLU\"\n",
    "}\n",
    "\n",
    "# Calculated settings\n",
    "cfg['n_heads'] = cfg['d_model']//cfg['d_head']\n",
    "cfg['d_mlp'] = 4 * cfg['d_model']\n",
    "\n",
    "# Custom settings not supported by EasyTransformer directly\n",
    "custom_cfg = {\n",
    "    'model_checkpoint_name': 'SoLU_1L_1024W_final_checkpoint.pth',\n",
    "    'device': 'cuda',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b452093-651d-4ffd-900e-8bfc06382072",
   "metadata": {},
   "source": [
    "### Model Setup\n",
    "\n",
    "This uses the `EasyTransformer` components, where possible (as they can be configured identically to the code that was used for training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f013bc5f-848b-4949-8fc5-32694887e777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): LayerNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_attn): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "        (hook_post_ln): HookPoint()\n",
       "        (ln): LayerNorm(\n",
       "          (hook_scale): HookPoint()\n",
       "          (hook_normalized): HookPoint()\n",
       "        )\n",
       "      )\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): RMSNormPre(\n",
       "    (hook_scale): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RMSNormPre(nn.Module):\n",
    "    \"\"\"RMS Pre Normalization\n",
    "    \n",
    "    This is RMS Normalization without the multiplation by a weights term, \n",
    "    as that has been folded into the next layer's weights instead.\"\"\"\n",
    "\n",
    "    def __init__(self, cfg, length):\n",
    "        super().__init__()\n",
    "        self.eps = cfg.eps\n",
    "        self.length = length\n",
    "        # self.w = nn.Parameter(torch.ones(length)) # Folded\n",
    "\n",
    "        # Adds a hook point for the normalization scale factor\n",
    "        self.hook_scale = HookPoint()  # [batch, pos]\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = self.hook_scale((x.pow(2).mean(-1, keepdim=True) +\n",
    "                                 self.eps).sqrt())  # [batch, pos, 1]\n",
    "        out = (x / scale) # * self.w # (folded)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class Transformer(EasyTransformer):\n",
    "    \"\"\"Transformer\n",
    "    \n",
    "    The checkpointed model had a few modifications from the\n",
    "    standard `EasyTransformer`, so we extend it and add these in here.\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg: EasyTransformerConfig):\n",
    "        super().__init__(\"custom\", cfg=cfg)\n",
    "        \n",
    "        # Custom tokenizer setup (different pad token) from trained model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neox-20b')\n",
    "        pad_token = '<PAD>'\n",
    "        self.tokenizer.add_special_tokens({'pad_token': pad_token})\n",
    "        \n",
    "        # Custom final layer norm (trained model used RMS Norm, and we've \n",
    "        # folded the weights out of this)\n",
    "        self.ln_final = RMSNormPre(self.cfg, self.cfg.d_model)\n",
    "   \n",
    "    def to_tokens(self, text):\n",
    "        return self.tokenizer(self.tokenizer.bos_token+text, return_tensors='pt')['input_ids'].to(custom_cfg['device'])\n",
    "\n",
    "    \n",
    "# Create the model\n",
    "model = Transformer(EasyTransformerConfig.from_dict(cfg))\n",
    "model.to(custom_cfg['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3708f5ca-51d5-4366-80c7-db4aa91fb880",
   "metadata": {},
   "source": [
    "## Load from the checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0797c77-e691-410b-ab95-45eba3faff3c",
   "metadata": {},
   "source": [
    "### Download Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cb296e-919e-4273-b375-89184849d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=16bqEZg9Oq0WT2xOcNS1HJkmR7qB2G14o\n",
      "To: /tmp/checkpoints/SoLU_1L_1024W_final_checkpoint.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 468M/468M [00:05<00:00, 80.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint provided by Neel Nanda\n",
    "checkpoint_url = \"https://drive.google.com/file/d/16bqEZg9Oq0WT2xOcNS1HJkmR7qB2G14o/view\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "checkpoint_dir = \"/tmp/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Download the checkpoint if it doesn't exist\n",
    "checkpoint_file = path.join(checkpoint_dir, custom_cfg['model_checkpoint_name'])\n",
    "if not path.exists(checkpoint_file):\n",
    "    gdown.download(checkpoint_url, checkpoint_file, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a163807-3abb-4483-90eb-927908430ff4",
   "metadata": {},
   "source": [
    "### Fold in weights and biases\n",
    "\n",
    "We fold the `LayerNorm` weights and biases in to the weights after them, for simplicty, as per [A Mathematical Framework for Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html#model-simplifications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8dd564-de63-400b-a51b-a9cc0ee99a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">odict_keys</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008000; text-decoration-color: #008000\">'embed.W_E'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pos_embed.W_pos'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'norm.w'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.norm1.w'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.norm1.b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.norm2.w'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.norm2.b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.attn.W_Q'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.attn.b_Q'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.attn.W_K'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.attn.b_K'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.attn.W_V'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.attn.b_V'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.attn.W_O'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.attn.b_O'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.attn.mask'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.attn.IGNORE'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.mlp.W_in'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.mlp.b_in'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.mlp.W_out'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.mlp.b_out'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.mlp.ln.w'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'blocks.0.mlp.ln.b'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'unembed.W_U'</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35modict_keys\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'embed.W_E'\u001b[0m, \u001b[32m'pos_embed.W_pos'\u001b[0m, \u001b[32m'norm.w'\u001b[0m, \u001b[32m'blocks.0.norm1.w'\u001b[0m, \u001b[32m'blocks.0.norm1.b'\u001b[0m, \u001b[32m'blocks.0.norm2.w'\u001b[0m, \n",
       "\u001b[32m'blocks.0.norm2.b'\u001b[0m, \u001b[32m'blocks.0.attn.W_Q'\u001b[0m, \u001b[32m'blocks.0.attn.b_Q'\u001b[0m, \u001b[32m'blocks.0.attn.W_K'\u001b[0m, \u001b[32m'blocks.0.attn.b_K'\u001b[0m, \n",
       "\u001b[32m'blocks.0.attn.W_V'\u001b[0m, \u001b[32m'blocks.0.attn.b_V'\u001b[0m, \u001b[32m'blocks.0.attn.W_O'\u001b[0m, \u001b[32m'blocks.0.attn.b_O'\u001b[0m, \u001b[32m'blocks.0.attn.mask'\u001b[0m, \n",
       "\u001b[32m'blocks.0.attn.IGNORE'\u001b[0m, \u001b[32m'blocks.0.mlp.W_in'\u001b[0m, \u001b[32m'blocks.0.mlp.b_in'\u001b[0m, \u001b[32m'blocks.0.mlp.W_out'\u001b[0m, \u001b[32m'blocks.0.mlp.b_out'\u001b[0m, \n",
       "\u001b[32m'blocks.0.mlp.ln.w'\u001b[0m, \u001b[32m'blocks.0.mlp.ln.b'\u001b[0m, \u001b[32m'unembed.W_U'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the state dictionary from the checkpoint\n",
    "sd = torch.load(checkpoint_file)\n",
    "print(sd.keys())\n",
    "\n",
    "# Fold in layer normalization weights & biases, for each layer (just one in the toy example)\n",
    "for layer in range(cfg['n_layers']):\n",
    "    # Pre-attention layer norm weights -> Query/Key/Value weights\n",
    "    pre_ln_w = sd[f\"blocks.{layer}.norm1.w\"]\n",
    "    W_Q_old = sd[f\"blocks.{layer}.attn.W_Q\"]\n",
    "    W_K_old = sd[f\"blocks.{layer}.attn.W_K\"]\n",
    "    W_V_old = sd[f\"blocks.{layer}.attn.W_V\"]\n",
    "    sd[f\"blocks.{layer}.attn.W_Q\"] = W_Q_old * pre_ln_w\n",
    "    sd[f\"blocks.{layer}.attn.W_K\"] = W_K_old * pre_ln_w\n",
    "    sd[f\"blocks.{layer}.attn.W_V\"] = W_V_old * pre_ln_w\n",
    "    \n",
    "    # Pre-attention layer norm biases -> Query/Key/Value biases\n",
    "    pre_ln_b = sd[f\"blocks.{layer}.norm1.b\"]\n",
    "    sd[f\"blocks.{layer}.attn.b_Q\"] = W_Q_old @ pre_ln_b + sd[f\"blocks.{layer}.attn.b_Q\"]\n",
    "    sd[f\"blocks.{layer}.attn.b_K\"] = W_K_old @ pre_ln_b + sd[f\"blocks.{layer}.attn.b_K\"]\n",
    "    sd[f\"blocks.{layer}.attn.b_V\"] = W_V_old @ pre_ln_b + sd[f\"blocks.{layer}.attn.b_V\"]\n",
    "    \n",
    "    # Post-attention layer weights/biases -> MLP weights/biases\n",
    "    W_in_old = sd[f\"blocks.{layer}.mlp.W_in\"]\n",
    "    sd[f\"blocks.{layer}.mlp.W_in\"] = W_in_old * sd[f\"blocks.{layer}.norm2.w\"]\n",
    "    sd[f\"blocks.{layer}.mlp.b_in\"] = W_in_old @ sd[f\"blocks.{layer}.norm2.b\"] \\\n",
    "                                        + sd[f\"blocks.{layer}.mlp.b_in\"]\n",
    "    \n",
    "    # Delete the weights/biases that are no longer used (as they're folded in)\n",
    "    del sd[f\"blocks.{layer}.norm1.w\"]\n",
    "    del sd[f\"blocks.{layer}.norm1.b\"]\n",
    "    del sd[f\"blocks.{layer}.norm2.w\"]\n",
    "    del sd[f\"blocks.{layer}.norm2.b\"]\n",
    "\n",
    "# Fold the post-blocks (pre-unembed) RMS norm weights -> unembed weights\n",
    "sd[\"unembed.W_U\"] *= sd[\"norm.w\"]\n",
    "del sd[\"norm.w\"] # Delete as no longer used (folded in)\n",
    "    \n",
    "# EasyTransformer has an additional bias term for the unembedding, so we simply set it to zero.\n",
    "sd[\"unembed.b_U\"] = torch.zeros(cfg['d_vocab'])\n",
    "\n",
    "# Load the state dict into the model\n",
    "model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba7396-663b-4401-aaec-ef7762b5ea73",
   "metadata": {},
   "source": [
    "## Find interesting activations\n",
    "\n",
    "A 1-layer model without an MLP can't do much more than skip trigrams. Whilst the MLP layer added may improve this a little, the prompts will still need to have quite simple answers.\n",
    "\n",
    "In this case we'll look for the ability of the model to close HTML tags. As an simple overview of how HTML tags work, whenever a tag is used (e.g. `<b>` for bold) it must be closed when you no longer want it to apply (e.g. `<b>bold text</b> normal text`).\n",
    "\n",
    "Note that `</` is a single token - so we can't use `<` as the last token and expect to see `/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3402d3fe-e412-4fcd-9bf8-a58c69467d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_token(prompt: str) -> str:\n",
    "    \"\"\"Run a forward pass to get the next token\"\"\"\n",
    "    logits = model(prompt, \"logits\")\n",
    "    log_probabilities = F.log_softmax(logits, dim=-1)\n",
    "    predictions = torch.argmax(log_probabilities, 2)\n",
    "    next_token = [model.tokenizer.decode(t) for t in predictions.squeeze()][-1]\n",
    "    probability = log_probabilities[-1]\n",
    "    return next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8b608e-250b-499a-802b-887775d0bda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">h1</span><span style=\"font-weight: bold\">&gt;</span>Title&lt;<span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">h1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mh1\u001b[0m\u001b[1m>\u001b[0mTitle<\u001b[35m/\u001b[0m\u001b[95mh1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">b</span><span style=\"font-weight: bold\">&gt;</span>Some bold text<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">b</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mb\u001b[0m\u001b[1m>\u001b[0mSome bold text\u001b[1m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mb\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">p</span><span style=\"font-weight: bold\">&gt;</span>An interesting paragraph<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">p</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mp\u001b[0m\u001b[1m>\u001b[0mAn interesting paragraph\u001b[1m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mp\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">table</span><span style=\"font-weight: bold\">&gt;&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">tr</span><span style=\"font-weight: bold\">&gt;&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">th</span><span style=\"font-weight: bold\">&gt;</span>Model name<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">th</span><span style=\"font-weight: bold\">&gt;</span>&lt;<span style=\"color: #800080; text-decoration-color: #800080\">/</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mtable\u001b[0m\u001b[1m>\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mtr\u001b[0m\u001b[1m>\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mth\u001b[0m\u001b[1m>\u001b[0mModel name\u001b[1m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mth\u001b[0m\u001b[1m>\u001b[0m<\u001b[35m/\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">li</span><span style=\"font-weight: bold\">&gt;</span>List item<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">li</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mli\u001b[0m\u001b[1m>\u001b[0mList item\u001b[1m<\u001b[0m\u001b[35m/\u001b[0m\u001b[95mli\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example prompts to run through the model\n",
    "prompts = [\n",
    "    \"<h1>Title</\",\n",
    "    \"<b>Some bold text</\",\n",
    "    \"<p>An interesting paragraph</\",\n",
    "    \"<table><tr><th>Model name</\",\n",
    "    \"<li>List item</\"\n",
    "]\n",
    "\n",
    "# Run each prompt (with a few tokens appended by the model)\n",
    "for prompt in prompts:\n",
    "    result = prompt\n",
    "    \n",
    "    additional_tokens = 2\n",
    "    for i in range(additional_tokens):\n",
    "        next_token = get_next_token(result)\n",
    "        result = result + next_token\n",
    "        \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ddaac-6c83-4660-85e3-1a5da84db463",
   "metadata": {},
   "source": [
    "## Find Important Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0759b65e-001a-426f-9686-c230ec285865",
   "metadata": {},
   "source": [
    "### MLP neurons\n",
    "\n",
    "The MLP activations are multiplied by $W_\\text{out}$ (and added to $b_\\text{out}$), added to the residual stream & sent through the RMS activation with weights/biases folded out (i.e. removed). It's then then multiplied by the unembedding weights ($W_U$) to get the logits. This means we can calculate the importance of the neurons by multiplying these weights by the neuron values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3bef1a3-855e-46c0-8cae-a4ff14cc950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_neuron_importance: dict[str, np.ndarray] = {} # {prompt: [importance of each neuron]}\n",
    "\n",
    "# Get the importance of each neuron, for the list of prompts\n",
    "for prompt in prompts:\n",
    "    # Setup the cache\n",
    "    cache = {}\n",
    "    model.cache_all(cache)\n",
    "\n",
    "    # Get the logits\n",
    "    logits = model(prompt, \"logits\")[0] # First batch item -> [ tokens x d_vocab ]\n",
    "    predictions = torch.argmax(logits, 1) # [ tokens ]\n",
    "\n",
    "    # Get the neurons\n",
    "    mlp_neurons = cache[f'blocks.{layer}.mlp.hook_post_ln'][0] # [ d_vocab x d_model ]\n",
    "\n",
    "    # Get the combined weights these are multiplied by\n",
    "    mlp_neuron_weights = sd['unembed.W_U'] @ sd['blocks.0.mlp.W_out'] # [ d_vocab x d_model ]\n",
    "\n",
    "    # Get the values for just the last token (the one we've predicted)\n",
    "    last_token_idx = predictions[-1].item()\n",
    "    last_token_weights = mlp_neuron_weights[last_token_idx]\n",
    "    last_token_mlp_neurons = mlp_neurons[-1]\n",
    "    last_token_neuron_importance = last_token_weights * last_token_mlp_neurons\n",
    "\n",
    "    # Calculate the importance as a percentage\n",
    "    importance_percentage = last_token_neuron_importance / last_token_neuron_importance.sum()\n",
    "    \n",
    "    # Add to the results\n",
    "    prompts_neuron_importance[prompt] = importance_percentage.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046ae3ae-fc4c-47e8-9ab0-1d55ad504f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;h1&gt;Title&lt;/</th>\n",
       "      <th>&lt;b&gt;Some bold text&lt;/</th>\n",
       "      <th>&lt;p&gt;An interesting paragraph&lt;/</th>\n",
       "      <th>&lt;table&gt;&lt;tr&gt;&lt;th&gt;Model name&lt;/</th>\n",
       "      <th>&lt;li&gt;List item&lt;/</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuron</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>0.096613</td>\n",
       "      <td>0.075791</td>\n",
       "      <td>0.110834</td>\n",
       "      <td>0.096130</td>\n",
       "      <td>0.183113</td>\n",
       "      <td>0.112496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>0.101765</td>\n",
       "      <td>0.238890</td>\n",
       "      <td>0.040109</td>\n",
       "      <td>0.017412</td>\n",
       "      <td>0.027491</td>\n",
       "      <td>0.085133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>0.024398</td>\n",
       "      <td>0.029209</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>0.034083</td>\n",
       "      <td>0.064888</td>\n",
       "      <td>0.037146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3810</th>\n",
       "      <td>0.051312</td>\n",
       "      <td>0.014371</td>\n",
       "      <td>0.056061</td>\n",
       "      <td>0.015946</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.036578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.059635</td>\n",
       "      <td>0.013014</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.095818</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.036182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>0.016477</td>\n",
       "      <td>0.031212</td>\n",
       "      <td>0.018242</td>\n",
       "      <td>0.060624</td>\n",
       "      <td>0.017517</td>\n",
       "      <td>0.028814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>0.064833</td>\n",
       "      <td>0.029711</td>\n",
       "      <td>0.038862</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>0.028325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.039516</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>0.080424</td>\n",
       "      <td>0.026818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>0.059883</td>\n",
       "      <td>0.016307</td>\n",
       "      <td>0.021545</td>\n",
       "      <td>0.017598</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>0.024599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>0.023691</td>\n",
       "      <td>-0.001589</td>\n",
       "      <td>0.058233</td>\n",
       "      <td>-0.005241</td>\n",
       "      <td>0.025868</td>\n",
       "      <td>0.020193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        <h1>Title</  <b>Some bold text</  <p>An interesting paragraph</  \\\n",
       "neuron                                                                    \n",
       "3444       0.096613             0.075791                       0.110834   \n",
       "1785       0.101765             0.238890                       0.040109   \n",
       "2538       0.024398             0.029209                       0.033149   \n",
       "3810       0.051312             0.014371                       0.056061   \n",
       "733        0.059635             0.013014                       0.009346   \n",
       "1292       0.016477             0.031212                       0.018242   \n",
       "1931       0.064833             0.029711                       0.038862   \n",
       "3369       0.005495             0.009700                       0.039516   \n",
       "2844       0.059883             0.016307                       0.021545   \n",
       "3313       0.023691            -0.001589                       0.058233   \n",
       "\n",
       "        <table><tr><th>Model name</  <li>List item</   average  \n",
       "neuron                                                          \n",
       "3444                       0.096130         0.183113  0.112496  \n",
       "1785                       0.017412         0.027491  0.085133  \n",
       "2538                       0.034083         0.064888  0.037146  \n",
       "3810                       0.015946         0.045200  0.036578  \n",
       "733                        0.095818         0.003096  0.036182  \n",
       "1292                       0.060624         0.017517  0.028814  \n",
       "1931                       0.001635         0.006584  0.028325  \n",
       "3369                      -0.001043         0.080424  0.026818  \n",
       "2844                       0.017598         0.007661  0.024599  \n",
       "3313                      -0.005241         0.025868  0.020193  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(prompts_neuron_importance)\n",
    "importance[\"average\"] = importance.sum(axis = 1)/len(importance.columns)\n",
    "\n",
    "# Format and sort\n",
    "importance.index.name = \"neuron\"\n",
    "importance = importance.sort_values(by=\"average\", ascending=False)\n",
    "\n",
    "importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53104a38-859b-40a8-ad02-65bc9a9782ff",
   "metadata": {},
   "source": [
    "From these results it's clear that a few neurons are important for working out how to close html tags (e.g. `3444`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b40bb39-ce9c-4aff-9bc9-e98d8b3ffec1",
   "metadata": {},
   "source": [
    "##### Visualising key neurons\n",
    "\n",
    "We'll now run the model with a larger chunk of html, and see which parts trigger these neurons most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "057689f7-dd22-469f-b06f-8dffdc53daa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([225, 4096])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the prompt\n",
    "prompt = \"\"\"<html>\n",
    "  <head>\n",
    "    <title>Dubious HTML Skills</title>\n",
    "  </head>\n",
    "  <div id=\"heading\">\n",
    "    <h1>\n",
    "      Dubious HTML Skills\n",
    "    </h1>\n",
    "    <p class=\"subtitle\" style=\"color: red;\">\n",
    "      By Alan Cooney\n",
    "    </p>\n",
    "  </div>\n",
    "  <hr/><!-- Self closing tag to add confusion -->\n",
    "  <div id=\"main\">\n",
    "    <h2>\n",
    "      An unordered list\n",
    "    </h2>\n",
    "    <div>\n",
    "      <ul>\n",
    "        <li>List item</li>\n",
    "        <li>Another interesting thing</li>\n",
    "      </ul>\n",
    "      \n",
    "      <h2>\n",
    "        An ordered list\n",
    "      </h2>\n",
    "      <ol>\n",
    "         <li>List item</li>\n",
    "        <li>Another interesting thing</li>\n",
    "      </ol>\n",
    "    </div>\n",
    "  </div>\n",
    "</html>\"\"\"\n",
    "\n",
    "# Convert to tokens\n",
    "tokens = model.to_tokens(prompt)\n",
    "\n",
    "# Setup the cache\n",
    "model.reset_hooks()\n",
    "cache = {}\n",
    "model.cache_all(cache)\n",
    "\n",
    "# Get the logits\n",
    "logits = model(prompt, \"logits\")[0] # [225, 50278]\n",
    "\n",
    "# Get the neurons\n",
    "mlp_neurons = cache[f'blocks.{layer}.mlp.hook_post_ln'][0] # [225, 4096]\n",
    "mlp_neurons.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c25be3-9544-4206-a802-49c857280dd9",
   "metadata": {},
   "source": [
    "### Visualising Neuron Activations\n",
    "\n",
    "We can now run a larger amount of html through the model, and see which parts of the text activate the most important neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72d93e8-3590-4f76-bc9a-42aa1d5f2d17",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### CSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "68b5286a-d486-47c2-8c86-9cfbcc094667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    /* Container */\n",
       "    .outerBlock {\n",
       "        position: relative;\n",
       "        display: inline-block;\n",
       "        width: auto;\n",
       "        padding: 0 5px;\n",
       "        margin: 1px 1px 1px -2px;\n",
       "        color: #fff;\n",
       "    }\n",
       "\n",
       "    /* Tooltip text */\n",
       "    .outerBlock .tooltiptext {\n",
       "      visibility: hidden;\n",
       "      width: auto;\n",
       "      background-color: black;\n",
       "      color: #fff;\n",
       "      text-align: center;\n",
       "      padding: 5px 0;\n",
       "      border-radius: 6px;\n",
       "\n",
       "      /* Position the tooltip text - see examples below! */\n",
       "      position: absolute;\n",
       "      z-index: 1;\n",
       "    }\n",
       "\n",
       "    /* Show the tooltip text when you mouse over the tooltip container */\n",
       "    .outerBlock:hover .tooltiptext {\n",
       "      visibility: visible;\n",
       "    }\n",
       "    </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    /* Container */\n",
    "    .outerBlock {\n",
    "        position: relative;\n",
    "        display: inline-block;\n",
    "        width: auto;\n",
    "        padding: 0 5px;\n",
    "        margin: 1px 1px 1px -2px;\n",
    "        color: #fff;\n",
    "    }\n",
    "\n",
    "    /* Tooltip text */\n",
    "    .outerBlock .tooltiptext {\n",
    "      visibility: hidden;\n",
    "      width: auto;\n",
    "      background-color: black;\n",
    "      color: #fff;\n",
    "      text-align: center;\n",
    "      padding: 5px 0;\n",
    "      border-radius: 6px;\n",
    "\n",
    "      /* Position the tooltip text - see examples below! */\n",
    "      position: absolute;\n",
    "      z-index: 1;\n",
    "    }\n",
    "\n",
    "    /* Show the tooltip text when you mouse over the tooltip container */\n",
    "    .outerBlock:hover .tooltiptext {\n",
    "      visibility: visible;\n",
    "    }\n",
    "    </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0e7bf4-2b85-48a7-b850-038d5bcc22ee",
   "metadata": {},
   "source": [
    "#### Neuron visualisation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d8f9df-2187-4898-a825-f096ca1d706b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;</th>\n",
       "      <td>0.003334</td>\n",
       "      <td>-0.016737</td>\n",
       "      <td>-0.294515</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>0.098163</td>\n",
       "      <td>0.039022</td>\n",
       "      <td>-0.040334</td>\n",
       "      <td>0.023278</td>\n",
       "      <td>-0.003482</td>\n",
       "      <td>0.019633</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035695</td>\n",
       "      <td>0.020276</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.025283</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.040952</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>-0.138265</td>\n",
       "      <td>-0.001714</td>\n",
       "      <td>-0.254747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>html</th>\n",
       "      <td>-0.004978</td>\n",
       "      <td>-0.013288</td>\n",
       "      <td>0.036868</td>\n",
       "      <td>0.003957</td>\n",
       "      <td>0.015209</td>\n",
       "      <td>-0.036187</td>\n",
       "      <td>0.053214</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>-0.001600</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001678</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>-0.002647</td>\n",
       "      <td>0.004438</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.115502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;</th>\n",
       "      <td>-0.007064</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>-0.024963</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>-0.002383</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>-0.002899</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.008157</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>-0.071425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n</th>\n",
       "      <td>-0.006206</td>\n",
       "      <td>-0.008013</td>\n",
       "      <td>-0.005806</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>0.025213</td>\n",
       "      <td>-0.012366</td>\n",
       "      <td>0.024937</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>-0.001676</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>-0.001562</td>\n",
       "      <td>0.010807</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>-0.056427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.010430</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>-0.102923</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.032190</td>\n",
       "      <td>0.009086</td>\n",
       "      <td>-0.003320</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001430</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>-0.002398</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>-0.004847</td>\n",
       "      <td>-0.065786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "token                                                                         \n",
       "<      0.003334 -0.016737 -0.294515  0.007116  0.098163  0.039022 -0.040334   \n",
       "html  -0.004978 -0.013288  0.036868  0.003957  0.015209 -0.036187  0.053214   \n",
       ">     -0.007064  0.003895 -0.024963  0.006397  0.022449  0.000035  0.006373   \n",
       "\\n    -0.006206 -0.008013 -0.005806  0.003963  0.025213 -0.012366  0.024937   \n",
       "      -0.010430  0.009132 -0.102923  0.002130  0.032190  0.009086 -0.003320   \n",
       "\n",
       "           7         8         9     ...      4086      4087      4088  \\\n",
       "token                                ...                                 \n",
       "<      0.023278 -0.003482  0.019633  ... -0.035695  0.020276 -0.005266   \n",
       "html   0.002984 -0.001600  0.004340  ... -0.001678  0.006071 -0.002647   \n",
       ">      0.004162 -0.002383  0.006273  ...  0.002674  0.000766 -0.002899   \n",
       "\\n     0.004367 -0.001676  0.001181  ...  0.032919  0.007068 -0.001562   \n",
       "       0.001905  0.001117  0.005754  ... -0.001430  0.009375 -0.002398   \n",
       "\n",
       "           4089      4090      4091      4092      4093      4094      4095  \n",
       "token                                                                        \n",
       "<      0.025283  0.007698  0.040952  0.008989 -0.138265 -0.001714 -0.254747  \n",
       "html   0.004438  0.003236  0.002682  0.003131  0.001807  0.000993  0.115502  \n",
       ">      0.009970  0.004745  0.005126  0.006045  0.008157  0.005207 -0.071425  \n",
       "\\n     0.010807  0.003854  0.000089  0.005600 -0.004245 -0.002289 -0.056427  \n",
       "       0.015501  0.004504  0.010736  0.005808  0.011842 -0.004847 -0.065786  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_token_strings(text: str) -> list[str]:\n",
    "    # Extremely hacky function to convert text into a list of each token (as text, not as a token index)\n",
    "    return model.tokenizer.batch_decode(model.tokenizer.encode(text), clean_up_tokenization_spaces=False)\n",
    "\n",
    "# Show as a dataframe \n",
    "mlp_neurons_df = pd.DataFrame(mlp_neurons.cpu())\n",
    "mlp_neurons_df[\"token\"] = pd.Series(text_to_token_strings(prompt))\n",
    "mlp_neurons_df.set_index([\"token\"], inplace=True)\n",
    "\n",
    "# Set sum to 1\n",
    "for col in mlp_neurons_df.columns:\n",
    "    mlp_neurons_df[col] = mlp_neurons_df[col]/sum(mlp_neurons_df[col])\n",
    "                                                  \n",
    "mlp_neurons_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d3aad1a3-269d-4fe2-baf3-092e1d14cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_neuron_activation(prompt: list[str], hook_cache: np.ndarray, neuron_index: int) -> None:\n",
    "    \"\"\"Visualise the activation of a specific neuron, for an input of text\n",
    "    \n",
    "    Args:\n",
    "        prompt (list[str]): The prompt as a list of string tokens (as text not as indicies)\n",
    "        hook_cache (np.ndarray): The cache from a specific hook \n",
    "            [ number_of_tokens x number_of_neurons ]\n",
    "        neuron_index (int): The index of the neuron that we're considering\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the activations as a percentage\n",
    "    # Note this will sum to 1, but some neurons will be negative\n",
    "    activations = hook_cache[:, neuron_index]\n",
    "    max = activations.max()\n",
    "    min = activations.min()\n",
    "    \n",
    "    # Print them\n",
    "    rendered_tokens = []\n",
    "    for idx, token in enumerate(prompt):\n",
    "              \n",
    "        # Handle new lines\n",
    "        if token == '\\n':\n",
    "            rendered_tokens.append('<br/>')\n",
    "        \n",
    "        # Handle spaces\n",
    "        elif re.match(r\"^ *$\", token):\n",
    "            rendered_tokens.append(token.replace(\" \", \"&nbsp;\"))\n",
    "        \n",
    "        # Otherwise render the token\n",
    "        else:\n",
    "            activation = activations[idx].item()\n",
    "        \n",
    "            green = int((activation /(max - min)) * 100 + 125) if activation > 0 else 125\n",
    "            red = int((activation / (max - min)) * 100 + 125) if activation < 0 else 125\n",
    "            color = (red, green, 125)\n",
    "\n",
    "            block = f\"\"\"<div style='background: rgb{color}' class=\"outerBlock\">\n",
    "                {html.escape(token)}\n",
    "                <span class=\"tooltiptext\">{html.escape(token)} : {round(float(activation) / (max - min), 4)}</span>\n",
    "            </div>\"\"\"\n",
    "            \n",
    "            rendered_tokens.append(block)\n",
    "    \n",
    "    return HTML(\"<div>\" + \"\\n\".join(rendered_tokens) + \"</div>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e6ea3393-6952-4cf9-a1aa-d4c24efdd1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_neurons_activations(prompt: list[str], hook_cache: np.ndarray, default_neuron: int) -> None:\n",
    "    \n",
    "    number_of_neurons = hook_cache.size()[1]\n",
    "    \n",
    "    neuron_dropdown = ipywidgets.Dropdown(\n",
    "        options=[i for i in range(number_of_neurons)],\n",
    "        value=default_neuron,\n",
    "        description='Neuron:',\n",
    "    )\n",
    "\n",
    "    display(neuron_dropdown)\n",
    "\n",
    "    out = ipywidgets.Output()\n",
    "    display(out)\n",
    "\n",
    "    with out:\n",
    "        html_output = visualise_neuron_activation(prompt, hook_cache, default_neuron)\n",
    "        display(html_output)\n",
    "\n",
    "    def neuron_dropdown_onchange(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            with out:\n",
    "                clear_output()\n",
    "                html_output = visualise_neuron_activation(prompt, hook_cache, change['new'])\n",
    "                display(html_output)\n",
    "\n",
    "    neuron_dropdown.observe(neuron_dropdown_onchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "48b3b574-8bcc-49a4-a316-f784e1300d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe3ab692fc84263b3dbe745d226c6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Neuron:', index=3444, options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa4f95421b8400aa2ad3aa2873b8b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualise_neurons_activations(text_to_token_strings(prompt), mlp_neurons.cpu(), 3444)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
